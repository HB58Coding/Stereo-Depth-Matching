{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "Y0D-AYBiJhRr",
        "outputId": "e310a340-5cbc-4ff9-e6b9-8bf22b12719f"
      },
      "outputs": [],
      "source": [
        "# Stereo Depth Estimation\n",
        "\n",
        "# Upload left/right images here\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdnpkWpqDidL"
      },
      "outputs": [],
      "source": [
        "# Required Imports\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BweNU5WqDvpX"
      },
      "outputs": [],
      "source": [
        "# Dataset for Folder-Based Stereo Pairs\n",
        "class StereoFolderDataset(Dataset):\n",
        "    def __init__(self, left_folder, right_folder, transform=None):\n",
        "        self.left_imgs = sorted([\n",
        "            os.path.join(left_folder, f) for f in os.listdir(left_folder)\n",
        "            if os.path.isfile(os.path.join(left_folder, f))\n",
        "        ])\n",
        "        self.right_imgs = sorted([\n",
        "            os.path.join(right_folder, f) for f in os.listdir(right_folder)\n",
        "            if os.path.isfile(os.path.join(right_folder, f))\n",
        "        ])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.left_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        left_img = Image.open(self.left_imgs[idx]).convert(\"RGB\")\n",
        "        right_img = Image.open(self.right_imgs[idx]).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            left_img = self.transform(left_img)\n",
        "            right_img = self.transform(right_img)\n",
        "\n",
        "        return left_img, right_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0ouQ37DDyjy"
      },
      "outputs": [],
      "source": [
        "# Deep Learning Stereo Network (for demonstration)\n",
        "class StereoNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StereoNet, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(6, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 1, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, left, right):\n",
        "        x = torch.cat((left, right), dim=1)  # Concatenate along channel axis\n",
        "        x = self.encoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUnOfEbxD4Tw"
      },
      "outputs": [],
      "source": [
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 512)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBtmKML2D6TW"
      },
      "outputs": [],
      "source": [
        "# Paths\n",
        "left_path = \"/content/stereo_data/left\"\n",
        "right_path = \"/content/stereo_data/right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCKheMoDLfkn"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "dataset = StereoFolderDataset(left_path, right_path, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQIcvkp8Lf1S",
        "outputId": "1387bdcf-abd6-402d-a5f5-3611e34ee22f"
      },
      "outputs": [],
      "source": [
        "# Load Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = StereoNet().to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1417
        },
        "id": "ImHhYuoTLgBR",
        "outputId": "7f159c6f-fd2e-4b48-e214-f3921e8e6460"
      },
      "outputs": [],
      "source": [
        "# Inference Loop\n",
        "with torch.no_grad():\n",
        "    for i, (left, right) in enumerate(dataloader):\n",
        "        left, right = left.to(device), right.to(device)\n",
        "        pred = model(left, right)\n",
        "        pred_np = pred.squeeze().cpu().numpy()\n",
        "\n",
        "        # Display\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.imshow(pred_np, cmap='plasma')\n",
        "        plt.title(f'Disparity Map - Image {i+1}')\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
